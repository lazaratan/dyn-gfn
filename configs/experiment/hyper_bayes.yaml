# @package _global_
#
# to execute this experiment run:
# python train.py experiment=linear_bayes

defaults:
  - override /model: bayesian_velocity
  - override /datamodule: linear_unidentifiable_velocity.yaml
  - override /logger:
      - wandb
      - csv
  - override /trainer: gpu
name: "hyper_gVI"

seed: 13

datamodule:
  batch_size: 100
  p: 20
  vars_to_deidentify: [0, 1, 2]
  sigma: 0.0
  sparsity: 0.9
  system: "linear"
  T: 2
  seed: 13

# best
model:
  lr: 1e-4 # og 1e-4
  alpha: 18.2208671582886 # TRAIN: 2, TEST: alpha_t after training  (bs=100 -> 18.2208671582886)
  l1_reg: 0.0025 # og 0.001
  kl_reg: 0.01
  svgd_reg: 0
  temperature: 0.01
  n_ens: 2000 # og 5000
  eval_batch_size: 2000 # og 5000
  k_hidden: 20
  hyper: "mlp" #["mlp", "invariant", "per_graph"]
  hyper_hidden_dim: [64, 64, 64]
  bias: True

  optimizer: "adam"

trainer:
  max_epochs: 1000
  check_val_every_n_epoch: 5

logger:
  wandb:
    tags: ["kl", "hyper", "linear", "bayes", "${name}", "v_final_3"]
